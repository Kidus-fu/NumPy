{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Data Preprocessing with NumPy\n",
    "\n",
    "In this notebook, we will explore how to preprocess datasets using NumPy. Data preprocessing is an essential step in any data analysis or machine learning pipeline. It involves cleaning, transforming, and preparing data to improve the quality of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2\\. Loading Data**\n",
    "\n",
    "You can load data into NumPy arrays from various sources, such as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset\n",
    "data = np.array([\n",
    "    [25, 170, 70],\n",
    "    [30, 165, 80],\n",
    "    [35, 180, np.nan],  # Missing value\n",
    "    [40, 175, 90],\n",
    "])\n",
    "print(\"Original Data:\\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3\\. Handling Missing Values**\n",
    "\n",
    "Missing values can be handled by replacing them with the mean, median, or a constant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with column mean\n",
    "col_mean = np.nanmean(data[:, 2])  # Mean of the third column (ignoring NaN)\n",
    "data[:, 2] = np.where(np.isnan(data[:, 2]), col_mean, data[:, 2])\n",
    "print(\"Data after handling missing values:\\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4\\. Normalizing Data**\n",
    "\n",
    "Normalization scales data to a specific range, often \\[0, 1\\], for uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 25., 170.,  70.],\n",
       "       [ 30., 165.,  80.],\n",
       "       [ 35., 180.,  80.],\n",
       "       [ 40., 175.,  90.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max normalization for the second column (heights)\n",
    "min_val = np.min(data[:, 1])\n",
    "max_val = np.max(data[:, 1])\n",
    "data[:, 1] = (data[:, 1] - min_val) / (max_val - min_val)\n",
    "print(\"Data after normalization:\\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5\\. Standardizing Data**\n",
    "\n",
    "Standardization transforms data to have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization for the third column (weights)\n",
    "mean = np.mean(data[:, 2])\n",
    "std_dev = np.std(data[:, 2])\n",
    "data[:, 2] = (data[:, 2] - mean) / std_dev\n",
    "print(\"Data after standardization:\\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Binning Data\n",
    "\n",
    "Binning groups continuous values into discrete bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning ages into categories\n",
    "bins = [20, 30, 40, 50]\n",
    "labels = [1, 2, 3]  # Represent categories\n",
    "data[:, 0] = np.digitize(data[:, 0], bins)\n",
    "print(\"Data after binning:\\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Removing Outliers\n",
    "\n",
    "Outliers are extreme values that can skew the results of data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where weight (third column) is more than 2 standard deviations from the mean\n",
    "z_scores = np.abs((data[:, 2] - np.mean(data[:, 2])) / np.std(data[:, 2]))\n",
    "data = data[z_scores < 2]\n",
    "print(\"Data after removing outliers:\\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Feature Scaling\n",
    "\n",
    "Feature scaling adjusts the range of variables for optimal performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all features to a range of [0, 1]\n",
    "data_min = np.min(data, axis=0)\n",
    "data_max = np.max(data, axis=0)\n",
    "data_scaled = (data - data_min) / (data_max - data_min)\n",
    "print(\"Data after feature scaling:\\n\", data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Saving Preprocessed Data\n",
    "\n",
    "Save the processed dataset for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a CSV file\n",
    "np.savetxt(\"../../data/processed_data.csv\", data, delimiter=\",\", fmt=\"%.2f\")\n",
    "print(\"Data saved to 'data/processed_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Handling Compressed Files\n",
    "\n",
    "Saving as a Compressed **.npz** File\n",
    "\n",
    "A compressed .npz file stores multiple NumPy arrays efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed data in a compressed format\n",
    "np.savez_compressed(\"../../data/processed_data.npz\", data=data_scaled)\n",
    "\n",
    "print(\"Data saved to 'processed_data.npz'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading from a Compressed **.npz** File\n",
    "\n",
    "You can easily load compressed data later for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from a compressed file\n",
    "loaded_data = np.load(\"../../data/processed_data.npz\")\n",
    "data_loaded = loaded_data['data']\n",
    "\n",
    "print(\"Loaded Data from 'processed_data.npz':\\n\", data_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Exporting Processed Data\n",
    "\n",
    "Saving to CSV\n",
    "\n",
    "If you prefer working with tools like Excel or other text-based formats, save the data as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a CSV file\n",
    "np.savetxt(\"processed_data.csv\", data_scaled, delimiter=\",\", fmt=\"%.2f\")\n",
    "print(\"Data saved to 'processed_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving to Text File\n",
    "\n",
    "For simple datasets, you can use a plain text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../../data/processed.txt\",data_scaled,fmt=\"%.2f\")\n",
    "print(\"Data saved to 'processed.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Loading CSV or Text Files\n",
    "\n",
    "Loading a CSV File\n",
    "\n",
    "You can reload a previously saved CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "loaded_csv = np.loadtxt(\"../../data/processed_data.csv\", delimiter=\",\")\n",
    "print(\"Loaded Data from 'processed_data.csv':\\n\", loaded_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a Text File\n",
    "\n",
    "Similarly, text files can be reloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text file\n",
    "loaded_txt = np.loadtxt(\"../../data/processed.txt\")\n",
    "print(\"Loaded Data from 'processed_data.txt':\\n\", loaded_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Cleaning Temporary or Old Files\n",
    "\n",
    "It's good practice to clean up unused files to save disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Delete unnecessary files\n",
    "if os.path.exists(\"processed_data.csv\"):\n",
    "    os.remove(\"processed_data.csv\")\n",
    "    print(\"'processed_data.csv' has been deleted.\")\n",
    "\n",
    "if os.path.exists(\"processed_data.txt\"):\n",
    "    os.remove(\"processed_data.txt\")\n",
    "    print(\"'processed_data.txt' has been deleted.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
